{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#render results (NORM)\n",
    "\n",
    "import math\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import cv2\n",
    "import io\n",
    "from PIL import Image\n",
    "import os\n",
    "import ffmpeg\n",
    "import gc\n",
    "import pyrender\n",
    "\n",
    "train_folder = \"train_6_24-06-22/\"\n",
    "results_folder = \"result/\"\n",
    "audio_folder = \"wav/\"\n",
    "video_woA_folder = \"renders/\"+ train_folder+ \"videos_no_audio/\"\n",
    "video_wA_folder = \"renders/\"+ train_folder+ \"videos_with_audio/\"\n",
    "frames_folder = \"renders/\"+ train_folder+ \"temp/frames/\"\n",
    "\n",
    "seqs = os.listdir(results_folder)\n",
    "\n",
    "fps = 25\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "\n",
    "cam = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1.414)\n",
    "camera_pose = np.array([[1.0, 0,   0.0,   0.03],\n",
    "                        [0.0,  -1.0, 0.0, -0.025],\n",
    "                        [0.0,  0.0,   1.0,   0.5],\n",
    "                        [0.0,  0.0, 0.0, 1.0]])\n",
    "light = pyrender.PointLight(color=[1.0, 1.0, 1.0], intensity=2.0)\n",
    "r = pyrender.OffscreenRenderer(640, 480)\n",
    "\n",
    "\n",
    "for seq in seqs:\n",
    "    if seq.endswith('.npy'):\n",
    "        video_woA_path = video_woA_folder + seq.split('.')[0] + '.mp4'\n",
    "        video_wA_path = video_wA_folder + seq.split('.')[0] + '.mp4'\n",
    "        video = cv2.VideoWriter(video_woA_path, fourcc, fps, (640, 480))\n",
    "        seq_path = results_folder + seq\n",
    "        subject_template_path = \"templates/\"+ seq.split('_')[0] + \".obj\"\n",
    "        audio = seq.split('_')[0]+'_'+seq.split('_')[1]+'.wav'\n",
    "        audio_path = audio_folder + audio\n",
    "        ref_mesh = trimesh.load_mesh(subject_template_path, process=False)\n",
    "\n",
    "        seq = np.load(seq_path)\n",
    "        seq = np.reshape(seq,(-1,70110//3,3))\n",
    "        ref_mesh.vertices = seq[0,:,:]\n",
    "        py_mesh = pyrender.Mesh.from_trimesh(ref_mesh)\n",
    "        for f in range(seq.shape[0]):\n",
    "            ref_mesh.vertices = seq[f,:,:]\n",
    "            py_mesh = pyrender.Mesh.from_trimesh(ref_mesh)\n",
    "            scene = pyrender.Scene()\n",
    "            scene.add(py_mesh)\n",
    "            scene.add(cam, pose=camera_pose)\n",
    "            scene.add(light, pose=np.eye(4))\n",
    "            color, _ = r.render(scene)\n",
    "            \n",
    "            output_frame = frames_folder + \"frame\" + str(f) + \".jpg\"\n",
    "            cv2.imwrite(output_frame, color)\n",
    "            frame = cv2.imread(output_frame)\n",
    "            video.write(frame)\n",
    "        video.release()\n",
    "        input_video = ffmpeg.input(video_woA_path)\n",
    "        input_audio = ffmpeg.input(audio_path)\n",
    "        ffmpeg.concat(input_video, input_audio, v=1, a=1).output(video_wA_path).run()\n",
    "        del video, seq, ref_mesh\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80c101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#render results (Scaled) Running code\n",
    "\n",
    "import math\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import cv2\n",
    "import io\n",
    "from PIL import Image\n",
    "import os\n",
    "import ffmpeg\n",
    "import gc\n",
    "import pyrender\n",
    "\n",
    "train_folder = \"train_14_22-08-22/\"\n",
    "results_folder = \"result/\"\n",
    "audio_folder = \"wav/\"\n",
    "video_woA_folder = \"renders/\"+ train_folder+ \"videos_no_audio/\"\n",
    "video_wA_folder = \"renders/\"+ train_folder+ \"videos_with_audio/\"\n",
    "frames_folder = \"renders/\"+ train_folder+ \"temp/frames/\"\n",
    "\n",
    "seqs = os.listdir(results_folder)\n",
    "\n",
    "fps = 25\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "\n",
    "cam = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1.414)\n",
    "camera_pose = np.array([[1.0, 0,   0.0,   0.00],\n",
    "                        [0.0,  -1.0, 0.0, 0.00],\n",
    "                        [0.0,  0.0,   1.0, -2.0],\n",
    "                        [0.0,  0.0, 0.0, 1.0]])\n",
    "\n",
    "\n",
    "light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=10.0)\n",
    "\n",
    "r = pyrender.OffscreenRenderer(640, 480)\n",
    "\n",
    "\n",
    "for seq in seqs:\n",
    "    if seq.endswith('.npy'):\n",
    "        video_woA_path = video_woA_folder + seq.split('.')[0] + '.mp4'\n",
    "        video_wA_path = video_wA_folder + seq.split('.')[0] + '.mp4'\n",
    "        video = cv2.VideoWriter(video_woA_path, fourcc, fps, (640, 480))\n",
    "        seq_path = results_folder + seq\n",
    "        subject_template_path = \"templates/\"+ seq.split('_')[0] + \".obj\"\n",
    "        audio = seq.split('_')[0]+'_'+seq.split('_')[1]+'.wav'\n",
    "        audio_path = audio_folder + audio\n",
    "        ref_mesh = trimesh.load_mesh(subject_template_path, process=False)\n",
    "        \n",
    "        seq = np.load(seq_path)\n",
    "        seq = np.reshape(seq,(-1,70110//3,3))\n",
    "        ref_mesh.vertices = seq[0,:,:]\n",
    "        py_mesh = pyrender.Mesh.from_trimesh(ref_mesh)\n",
    "        for f in range(seq.shape[0]):\n",
    "            ref_mesh.vertices = seq[f,:,:]\n",
    "            py_mesh = pyrender.Mesh.from_trimesh(ref_mesh)\n",
    "            scene = pyrender.Scene()\n",
    "            scene.add(py_mesh)\n",
    "            \n",
    "            scene.add(cam, pose=camera_pose)\n",
    "            scene.add(light, pose=camera_pose)\n",
    "            color, _ = r.render(scene)\n",
    "            \n",
    "            output_frame = frames_folder + \"frame\" + str(f) + \".jpg\"\n",
    "            cv2.imwrite(output_frame, color)\n",
    "            frame = cv2.imread(output_frame)\n",
    "            video.write(frame)\n",
    "        video.release()\n",
    "        \n",
    "        input_video = ffmpeg.input(video_woA_path)\n",
    "        input_audio = ffmpeg.input(audio_path)\n",
    "        ffmpeg.concat(input_video, input_audio, v=1, a=1).output(video_wA_path).run()\n",
    "        del video, seq, ref_mesh\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f92a3c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]]\n",
      "\n",
      " [[nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]]\n",
      "\n",
      " [[nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]]\n",
      "\n",
      " [[nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]]\n",
      "\n",
      " [[nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]\n",
      "  [nan nan nan]]]\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "ffmpeg error (see stderr output for detail)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16492/1805016226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0minput_video\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mffmpeg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_woA_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0minput_audio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mffmpeg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mffmpeg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_video\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_audio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_wA_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_mesh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py38anim\\lib\\site-packages\\ffmpeg\\_run.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(stream_spec, cmd, capture_stdout, capture_stderr, input, quiet, overwrite_output)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ffmpeg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mError\u001b[0m: ffmpeg error (see stderr output for detail)"
     ]
    }
   ],
   "source": [
    "#render results (Scaled + HuBert + from raw wav -> fps=50)\n",
    "\n",
    "import math\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import cv2\n",
    "import io\n",
    "from PIL import Image\n",
    "import os\n",
    "import ffmpeg\n",
    "import gc\n",
    "import pyrender\n",
    "\n",
    "train_folder = \"train_8_24-06-22_Downstream_1/\"\n",
    "results_folder = \"result/\"\n",
    "audio_folder = \"wav/\"\n",
    "video_woA_folder = \"renders/\"+ train_folder+ \"videos_no_audio/\"\n",
    "video_wA_folder = \"renders/\"+ train_folder+ \"videos_with_audio/\"\n",
    "frames_folder = \"renders/\"+ train_folder+ \"temp/frames/\"\n",
    "\n",
    "seqs = os.listdir(results_folder)\n",
    "\n",
    "fps = 50\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "\n",
    "cam = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1.414)\n",
    "camera_pose = np.array([[1.0, 0,   0.0,   0.00],\n",
    "                        [0.0,  -1.0, 0.0, 0.00],\n",
    "                        [0.0,  0.0,   1.0, -2.0],\n",
    "                        [0.0,  0.0, 0.0, 1.0]])\n",
    "\n",
    "\n",
    "light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=10.0)\n",
    "\n",
    "r = pyrender.OffscreenRenderer(640, 480)\n",
    "\n",
    "\n",
    "for seq in seqs:\n",
    "    if seq.endswith('.npy'):\n",
    "        video_woA_path = video_woA_folder + seq.split('.')[0] + '.mp4'\n",
    "        video_wA_path = video_wA_folder + seq.split('.')[0] + '.mp4'\n",
    "        video = cv2.VideoWriter(video_woA_path, fourcc, fps, (640, 480))\n",
    "        seq_path = results_folder + seq\n",
    "        subject_template_path = \"templates/\"+ seq.split('_')[0] + \".obj\"\n",
    "        audio = seq.split('_')[0]+'_'+seq.split('_')[1]+'.wav'\n",
    "        audio_path = audio_folder + audio\n",
    "        ref_mesh = trimesh.load_mesh(subject_template_path, process=False)\n",
    "        \n",
    "        seq = np.load(seq_path)\n",
    "        seq = np.reshape(seq,(-1,70110//3,3))\n",
    "#         print(seq)\n",
    "        ref_mesh.vertices = seq[0,:,:]\n",
    "        py_mesh = pyrender.Mesh.from_trimesh(ref_mesh)\n",
    "        for f in range(seq.shape[0]):\n",
    "            ref_mesh.vertices = seq[f,:,:]\n",
    "            py_mesh = pyrender.Mesh.from_trimesh(ref_mesh)\n",
    "            scene = pyrender.Scene()\n",
    "            scene.add(py_mesh)\n",
    "            \n",
    "            scene.add(cam, pose=camera_pose)\n",
    "            scene.add(light, pose=camera_pose)\n",
    "            color, _ = r.render(scene)\n",
    "            \n",
    "            output_frame = frames_folder + \"frame\" + str(f) + \".jpg\"\n",
    "            cv2.imwrite(output_frame, color)\n",
    "            frame = cv2.imread(output_frame)\n",
    "            video.write(frame)\n",
    "        video.release()\n",
    "        \n",
    "        input_video = ffmpeg.input(video_woA_path)\n",
    "        input_audio = ffmpeg.input(audio_path)\n",
    "        ffmpeg.concat(input_video, input_audio, v=1, a=1).output(video_wA_path).run()\n",
    "        del video, seq, ref_mesh\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ff9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
